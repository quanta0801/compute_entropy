{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename):\n",
    "    \"\"\"Download filename from url\"\"\"\n",
    "    print(\"Downloading {}, from: {}\".format(filename, url))\n",
    "    res = requests.get(url, allow_redirects=True)\n",
    "    open(filename, \"wb\").write(res.content)\n",
    "\n",
    "def unzip_file(filezip, datadir):\n",
    "    \"\"\"Unzip provided zipfile into datadir\"\"\"\n",
    "    print(\"Extracting: {}\".format(filezip))\n",
    "    with zipfile.ZipFile(filezip, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(datadir)\n",
    "    print(\"{} extracted\".format(filezip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdb_data(ddir=\"\"):\n",
    "    \"\"\"Check if HDB resale file exists, if not, download from data.gov.sg. Returns data as pandas df.\"\"\"\n",
    "    url = \"https://data.gov.sg/dataset/7a339d20-3c57-4b11-a695-9348adfd7614/download\"\n",
    "    filezip = os.path.join(ddir, \"resale-flat-prices.zip\")\n",
    "    datadir = os.path.join(ddir, \"resale-flat-prices\")\n",
    "    filename = \"resale-flat-prices-based-on-registration-date-from-jan-2015-onwards.csv\"\n",
    "    filepath = os.path.join(datadir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"{} does not exist, checking for zipfile: {}\".format(filepath, filezip))\n",
    "        if not os.path.exists(filezip):\n",
    "            download_file(url, filezip)\n",
    "        unzip_file(filezip, datadir)\n",
    "    print(\"Reading data from: {}\".format(filepath))\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "def load_taxi_data(ddir=\"\"):\n",
    "    \"\"\"Check if taxi trip file exists, if not, download from data.cityofnewyork.us. Returns data as pandas df.\"\"\"\n",
    "    url = \"https://data.cityofnewyork.us/resource/uacg-pexx.json\"\n",
    "    filename = \"2016_Yellow_Taxi_Trip_Data.json\"\n",
    "    filepath = os.path.join(ddir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        download_file(url, filepath)\n",
    "    print(\"Reading data from: {}\".format(filepath))\n",
    "    data = pd.read_json(filepath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: resale-flat-prices/resale-flat-prices-based-on-registration-date-from-jan-2015-onwards.csv\n",
      "Downloading 2016_Yellow_Taxi_Trip_Data.json, from: https://data.cityofnewyork.us/resource/uacg-pexx.json\n",
      "Reading data from: 2016_Yellow_Taxi_Trip_Data.json\n"
     ]
    }
   ],
   "source": [
    "hdb_data = load_hdb_data()\n",
    "taxi_data = load_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(data):\n",
    "    \"\"\"Compute entropy of data provided.\n",
    "    \n",
    "    Args:\n",
    "      data (list or list-like):  list of categorical data.\n",
    "      \n",
    "    Returns:\n",
    "      float: Computed entropy.\n",
    "    \"\"\"\n",
    "    length = len(data)\n",
    "    count_dict = {}\n",
    "    for elem in data:\n",
    "        count_dict[elem] = count_dict.get(elem, 0) + 1\n",
    "    \n",
    "    entropy = 0\n",
    "    for count in count_dict.values():\n",
    "        prob = count / float(length)\n",
    "        entropy += - prob * math.log(prob, 2)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def bucketise_data(data, n_buckets):\n",
    "    \"\"\"Bucketise provided numeric data into n_buckets of equal width\"\"\"\n",
    "    data = list(data)\n",
    "    max_v = max(data)\n",
    "    min_v = min(data)\n",
    "    increment = float(max_v - min_v) / n_buckets\n",
    "    buck_thres = [min_v+(i+1)*increment for i in range(n_buckets)]\n",
    "    data.sort()\n",
    "    bucket_no = 0\n",
    "    buck_data = []\n",
    "    for elem in data:\n",
    "        if elem <= buck_thres[bucket_no]:\n",
    "            buck_data.append(bucket_no)\n",
    "        else:\n",
    "            bucket_no += 1\n",
    "    return buck_data\n",
    "\n",
    "def pd_compute_entropy(df, col, to_bucketise=False, n_buckets=5):\n",
    "    \"\"\"Compute entropy of provided column of pandas df.\n",
    "    \n",
    "    Args:\n",
    "      df (pandas.DataFrame): pandas DataFrame.\n",
    "      col (str): column name of interest.\n",
    "      to_bucketise (bool): whether to bucketise data. Only for numeric data.\n",
    "      n_buckets (int): number of buckets to breakdown numeric data.\n",
    "    \n",
    "    Returns:\n",
    "      float: Computed entropy.\n",
    "    \"\"\"\n",
    "    data = df[col]\n",
    "    if to_bucketise:\n",
    "        data = bucketise_data(data, n_buckets)\n",
    "    return compute_entropy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6813042691824056"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy(hdb_data[\"storey_range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.894131402423329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_compute_entropy(hdb_data, \"flat_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10661864154013403"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_compute_entropy(taxi_data, \"dropoff_latitude\", to_bucketise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9572930059549053"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_compute_entropy(taxi_data, \"payment_type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
